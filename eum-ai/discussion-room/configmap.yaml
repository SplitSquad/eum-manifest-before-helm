apiVersion: v1
kind: ConfigMap
metadata:
  name: discussion-room-config
  namespace: eum-ai
data:
  APP_NAME: "EUM-DISCUSSION-ROOM"
  PORT: "8000"
  EUREKA_URL: "http://discovery.eum-backend.svc.cluster.local:8761/eureka"
  eureka-ip: http://discovery.eum-backend.svc.cluster.local:8761/eureka
  eureka-instance-host: "discussion-room.eum-ai.svc.cluster.local"
  eureka-app-name: "EUM-DISCUSSION-ROOM"
  eureka-instance-port: "8000"
  EUREKA_INSTANCE_PREFER_IP_ADDRESS: "true"
  LIGHTWEIGHT_LLM_PROVIDER: "ollama"
  HIGH_PERFORMANCE_LLM_PROVIDER: "ollama"
  GROQ_LIGHTWEIGHT_MODEL: "gemma2-9b-it"
  GROQ_HIGHPERFORMANCE_MODEL: "gemma2-9b-it"
  LIGHTWEIGHT_OLLAMA_URL: "http://ollama-service:11434"
  LIGHTWEIGHT_OLLAMA_MODEL: "gemma3:1b"
  LIGHTWEIGHT_OLLAMA_TIMEOUT: "20"
  HIGH_PERFORMANCE_OLLAMA_URL: "http://ollama-service:11434"
  HIGH_PERFORMANCE_OLLAMA_MODEL: "gemma3:1b"
  HIGH_PERFORMANCE_OLLAMA_TIMEOUT: "60"
  LIGHTWEIGHT_OPENAI_MODEL: "gpt-3.5-turbo"
  LIGHTWEIGHT_OPENAI_TIMEOUT: "30"
  HIGH_PERFORMANCE_OPENAI_MODEL: "gpt-4-turbo"
  HIGH_PERFORMANCE_OPENAI_TIMEOUT: "60"
  S3_REGION: "ap-northeast-2"
  S3_BUCKET_NAME: "eum-msa-bucket"
  PYTHONPATH: "${PYTHONPATH}:."
  host: "0.0.0.0"
  port: "8000"
  debug: "True" 